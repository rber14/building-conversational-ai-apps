read : https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex

RAG - RAG (Retrieval-Augmented Generation) in LLMs is a powerful technique that connects large language models to external, up-to-date knowledge sources, allowing them to provide more accurate, factual, and context-specific answers by retrieving relevant information before generating a response.

Limitation - Context window size, recalling information (lost in the middle problem)

text to SQL -

- provide llm more context of tables, we need to generate accurate SQL

Search:

Key word search - find text that contains specific terms.
                - Levarge sparse vector
                - each element in vector represents a unique word.

Similarity search - sparse and dense vectors 
                    - can combine both search types.
                  - vector operations are reletivly cheap.
re ranking - improves search quality. order result based on similarity.

text to SQL - need to know and understand the data. 
            - Solve range of problems like: Interpret question, understand schemas, and generate correct sql.
            - Understand how to best answer with the information available.
            - Question Understanding.
                - Handle ambiguity.
            - Mapping to the database. Schema comprehension. 
                - once model understand that is being ask and where to get the information. The model needs to generate accurate sql.
            - Query formulation and validation.
            - 

Dashboards - only display what they are built to display.
  - Analyst could become very busy, but building a dashboard could become death by dashboard by freezing decsions. 
- With natural langauge you could solve this.



- 80 percent of unstructured data is not being used?
- 

Cortex search:
- RAG find info llm needs
    - High quality rag

cortex is optimized for low latency. 
  - cortex search takes hy brid search approach
  - Key word = excat phrases, semantic = helps us disocover when doc answers question but with diffrent works.
            --- Semantic search goes beyond keyword matching. Instead of looking for exact words, it understands the meaning 
                      of the query and retrieves results that are conceptually related.
  - coretez search than re ranks the result. 
  - user control
      - only users that have access to not only the srevice but the data
      - users must be granted exlpicit access.
  - target lag, allows us to control freshness of cortex service.
      - no old table
      - we need a fresh search!
task
  - parse doc
  - extract full text and table, maintain doc struct, support lnagayges, accurate. Lay ON, Lay OFF - choose layout ON to keep structure of doc
        --
          Snowflake’s Layout Mode (part of Document AI) is designed to interpret the structure of unstructured documents. It doesn’t just read text; it understands layouts like tables, signatures, checkboxes, and paragraph formatting. 
          This allows it to handle invoices, contracts, and even handwritten notes by extracting structured data from each type
        --
  - split text, split long documents, preserve document structure, experiment with multiple chunking strategies.  Overlap, allows chunks to retain some infor of the next chunck.

- you pay based on the size of your data, and meter by the second. 
    - add or change documents more cost
- 

LOADING unstructured data.

- text splitting !

- chunck size determined on experimentation. Overlap to ensure each chunck has context about previous
        ---
            In a retrieval‑augmented generation (RAG) model, documents are split into smaller pieces (“chunks”) before being embedded and stored in a vector database. 
            When you ask a question, the system retrieves the most relevant chunks and feeds them into the language model.
        ---

READINGS
Parse Document: 
https://docs.snowflake.com/en/sql-reference/functions/parse_document-snowflake-cortex

Split Text recursive character:
https://docs.snowflake.com/sql-reference/functions/split_text_recursive_character-snowflake-cortex

- @instrument() 
  - 

- Complex
  - 
- How to measure if RAG is running well???????
        - How to measure success?
  - 1 register

RAG TRIAD = QUERY -> (context relevance : is the retrieved context relevant to the query) -> context -> (Groundedness : is the response supported by the context) -> Response -> (Answer Relevance: is the answer relevant to the query? ) -> query

- LMS JUDGE
    - pass text and provide grading criteria
    - We can bench mark llm judge against human evaluation
*
Objective Accuracy Measurement

    Ground‑truth metrics compare retrieved chunks and generated answers against a known correct dataset.
            - This gives you a clear, unbiased measure of whether the system is returning the right information.
            - Ground‑truth metrics allow you to compare different embedding models, chunk sizes, or re‑ranking strategies in a standardized way.
            - You can run A/B tests and know which configuration is objectively better.

READ:

 Dive deep into the inner workings of RAG Triad LLM Judge evaluators including prompts and benchmark results.
https://www.snowflake.com/en/engineering-blog/benchmarking-LLM-as-a-judge-RAG-triad-metrics/

 Learn more about how LLM judges can be benchmarked and optimized against human evaluations.
https://www.snowflake.com/en/engineering-blog/eval-guided-optimization-llm-judges-rag-triad/

- Use STREAMS to watch for changes in stage - as new docs come in 
  - set task
   - then complete steps in tasks 
          - make sure to resume the task, when created task start as susspended

READING MATERIAL:

STEAMS: https://docs.snowflake.com/en/user-guide/streams-intro
TASKS: https://docs.snowflake.com/en/user-guide/tasks-intro

Streamlit


Overview:

- ASK questions using unstructured data
- Buit a RAG using cortex search
- Imporve the accuracy of the RAG
- Load unstructured data into snowflake stage
  - special pdf formater tool
- parsed documents to text
- chunked the text for RAG
- build a pipeline to keep data fresh
- measure success of your RAG

Module 3

- Find out what is really needed. Ask extremely clarifying questions! WHAT EXACTLY IS SUCCESS!
          - Death by dashboard.
- Build an app that you can use natural langauge instead of a dashboard. 






